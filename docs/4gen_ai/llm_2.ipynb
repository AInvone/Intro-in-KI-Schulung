{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bb4456-5dc2-440c-9320-4af43e032aeb",
   "metadata": {},
   "source": [
    "# Hands-on Beispiel LLM (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a74c0f-6038-4871-9038-df59a4be02a1",
   "metadata": {},
   "source": [
    "### 2. Fine-tuning - Anpassung an juristische Fachtexte\n",
    "##### --- Juristische Fragen an ein fine-tuned Modell (Lokale LLM)\n",
    "\n",
    "In diesem Abschnitt fine-tunen wir das Modell `dbmdz/german-gpt2` und stellen ihm die gleichen zwei juristischen Fragen zum AI Act wie im Baseline-Notebook.\n",
    "\n",
    "Ziel ist es, dass das feingetunte Modell (llm-2) nun fundiertere und korrekte Antworten liefert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0f45fe-361d-4965-a821-e69419fced67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falls noch nicht installiert \n",
    "\n",
    "import sys\n",
    "# !{sys.executable} -m pip install transformers datasets\n",
    "# !{sys.executable} -m pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e552b09-89c0-4168-8e6c-c59babe09ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minye/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/minye/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b807925-978d-4d97-8765-ad2beaf99097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Modell und Tokenizer (das Basis-Modell bleibt identisch)\n",
    "model_name = \"dbmdz/german-gpt2\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = model.bfloat16()\n",
    "\n",
    "# Da GPT-2-Modelle oft keinen expliziten Padding-Token besitzen, setzen wir hier den EOS-Token als Padding-Token.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Konfiguriere pad_token_id im Modell \n",
    "# (braucht man, wenn das Modell noch nicht standardmäßig für den Umgang mit dem Padding-Token eingestellt ist)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3dcaf-e281-4c42-a60c-069a8812b65c",
   "metadata": {},
   "source": [
    "## Domänenspezifischer Datensatz: Auszüge aus dem AI Act\n",
    "Wir extrahieren zwei wichtige Absätze aus dem AI Act, die juristische Fachtermini und Anforderungen beinhalten. \n",
    "\n",
    "Hinweis: Die folgenden Textabschnitte sind exemplarisch und basieren auf öffentlich zugänglichen Informationen zum AI Act, z.B.: \"https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035f7eae-df3e-4b98-8f5d-4bec1fcc71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgewählte Absätze aus dem AI Act (Beispiele)\n",
    "ai_act_texts = [\n",
    "    \"Artikel 1 – Anwendungsbereich: \n",
    "    Diese Verordnung gilt für KI-Systeme, die in der Europäischen Union in Verkehr gebracht oder in Betrieb genommen werden, und legt die grundlegenden Anforderungen an Sicherheit, Transparenz und Verantwortlichkeit fest.\",\n",
    "    \"Artikel 2 – Risikoklassifizierung: \n",
    "    KI-Systeme werden in Abhängigkeit von ihrem potenziellen Risiko in verschiedene Kategorien eingeteilt. Hochrisiko-KI-Systeme unterliegen strengen Anforderungen an ihre Konzeption, Entwicklung und den Betrieb, um die Sicherheit und den Schutz der Grundrechte zu gewährleisten.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bc7dc9-f3e6-41bd-8e9f-f8f1c5aae526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domänenspezifischer Datensatz erstellt:\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Erstelle ein Dataset aus den Auszügen\n",
    "data_dict = {\"text\": ai_act_texts}\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "print(\"Domänenspezifischer Datensatz erstellt:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e420718-e911-4b18-a316-65f2ac1f7b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 100.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenisierter Datensatz:\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Tokenisiere den Datensatz\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "print(\"Tokenisierter Datensatz:\")\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339445b0-2592-4fba-968d-3e6b3180a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle einen DataCollator für das Language Modeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd9e4e9-b9d5-4f6c-9ec3-193b0b79b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere Trainingsargumente – das Fine-Tuning erfolgt exemplarisch über wenige Epochen\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llm_ai_act_finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    save_steps=5,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40e68eb-7c6f-436f-a04a-004686432039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere den Trainer für das Fine-Tuning\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c146974-ab45-433b-b964-811f0a668c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte das Fine-Tuning mit AI Act-Daten...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.877900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.870800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning abgeschlossen.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50265, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Starte das Fine-Tuning\n",
    "print(\"Starte das Fine-Tuning mit AI Act-Daten...\")\n",
    "trainer.train()\n",
    "print(\"Fine-Tuning abgeschlossen.\")\n",
    "\n",
    "# Modell auf die CPU schieben und und alle Eingaben auf der CPU verarbeiten \n",
    "model.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989decaa-3b68-4de2-b720-a54305f615a7",
   "metadata": {},
   "source": [
    "## Test: Juristische Fragen erneut stellen\n",
    "Nun stellen wir wieder dieselben Fragen wie in llm-1, um zu prüfen, ob das feingetunte Modell (llm-2) bessere Antworten liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8df80e0e-f94c-4926-bbf5-0040314fd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids, max_length=150, temperature=0.7, do_sample=True)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fdd2b04-7780-4342-b91a-8fd4b3fc4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Welche Anforderungen stellt der AI Act an Hochrisiko-KI-Systeme?\",\n",
    "    \"Was versteht man unter Transparenz gemäß dem AI Act?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79d1b1b5-0ef8-434d-9caa-61ae0b9f323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== llm-2: Feingetuntes Modell ===\n",
      "\n",
      "Frage: Welche Anforderungen stellt der AI Act an Hochrisiko-KI-Systeme?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antwort: Welche Anforderungen stellt der AI Act an Hochrisiko-KI-Systeme?\n",
      "Die AI-Systeme in der Lebensmittelindustrie werden seit Jahren an verschiedenen Stellen in der Lebensmittelindustrie eingesetzt.\n",
      "Die AI-Systeme bieten einen sehr guten Überblick über die gesamten Anforderungen in Bezug auf Sicherheit, Zuverlässigkeit und Flexibilität.\n",
      "Als die erste Anwendung wurde im Jahr 2001 die AI-Software für die Lebensmittelindustrie entwickelt.\n",
      "Mittlerweile kann das System im Bereich der Lebensmittel-Technologie bereits in ca. 100 verschiedenen Anwendungen eingesetzt werden.\n",
      "Im Folgenden werden einige der größten Herausforderungen der Lebensmittelindustrie umrissen, die eine weitere Anwendung erfordern.\n",
      "Es gibt ein grundlegendes Problem, das eine Reihe von Anwendungen erfordert.\n",
      "Das Problem der Zuverlässigkeit ist der Grund dafür, dass Produkte in\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Frage: Was versteht man unter Transparenz gemäß dem AI Act?\n",
      "\n",
      "Antwort: Was versteht man unter Transparenz gemäß dem AI Act?\n",
      "Der Bericht von der Tagung des Europäischen Rates im März 1999 in Wien ist ein Beitrag zur Diskussion über die Zukunft der EU.\n",
      "Die EU-Erweiterung wird als eine der wichtigsten Herausforderungen betrachtet, mit denen die Regierungen der Mitgliedstaaten konfrontiert sind.\n",
      "Aber bei der Gestaltung der künftigen EU-Nachbarschaftspolitik geht es nicht nur um die Erweiterung.\n",
      "Die EU ist vor allem ein sozialer Raum.\n",
      "Während die EU-Politik auf die Bedürfnisse der Bürger ausgerichtet ist, sollen diese Bedürfnisse durch die Erweiterung nicht nur in ihrer eigenen Region, sondern auch in ihren Nachbarregionen befriedigt werden.\n",
      "Die EU-Politik der EU-Erweiterung, die sich auf die Bedürfnisse der Bürger in ihren eigenen Regionen konzentriert, ist ein\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== llm-2: Feingetuntes Modell ===\\n\")\n",
    "for q in questions:\n",
    "    print(\"Frage:\", q)\n",
    "    print() \n",
    "    answer = ask_question(q)\n",
    "    print(\"Antwort:\", answer)\n",
    "    print(\"-\" * 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7eac0-469f-4474-8886-da42231d854c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
